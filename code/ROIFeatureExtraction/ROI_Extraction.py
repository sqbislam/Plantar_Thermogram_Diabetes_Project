# -*- coding: utf-8 -*-
"""Thermal Imaging Annotation prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GZy0g7MuXSG42BjmNbxHFI-7ySZSGMuG

We'll start with some common imports
"""

from google.colab import drive
from pathlib import Path
import pathlib
import numpy as np
import shutil
import os
import pandas as pd
drive.mount('/content/drive')


import matplotlib.pyplot as plt
import cv2
from google.colab.patches import cv2_imshow

from pandas.core.common import random_state
import seaborn as sns
from sklearn import svm
from sklearn.model_selection import GridSearchCV

from sklearn.model_selection import train_test_split
from sklearn.linear_model import Lasso, LogisticRegression
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import StandardScaler

from skimage.feature import greycomatrix, greycoprops
from skimage import data

from numpy import sort
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn import metrics
from sklearn.model_selection import KFold, RepeatedKFold, LeaveOneOut
from sklearn.model_selection import cross_val_score
import csv

DATA_PATH = "/content/drive/MyDrive/UM_MSC/Research_Thermal_Imaging/data/ThermoDataBase"
GENERAL_DATA_CSV = "/content/drive/MyDrive/UM_MSC/Research_Thermal_Imaging/data/ThermoDataBase/Plantar Thermogram Database.xlsx"
IMG_PATH = DATA_PATH + "/images"
TEST_PATH = DATA_PATH + "/test"
TEST_IMAGE_PATH = TEST_PATH + "/images"
ANNOT_PATH = TEST_PATH + "/annotation_results"
CSV_FILE_PATH = DATA_PATH + "/csvs/"

"""## Read Excel file containing information about each patient
##### Age, Weight, Gender, Mean temps

"""

R_CG_Data = pd.read_excel(GENERAL_DATA_CSV, sheet_name=0,skiprows=[1,47], usecols=[2,3,4,5,6,12]).fillna(method ='pad')
R_CG_Data = R_CG_Data.rename(columns={"RIGHT FOOT": "Overall Mean(Right)", "LEFT FOOT": "Overall Mean(Left)", "IMC":"BMI"})
R_DM_Data = pd.read_excel(GENERAL_DATA_CSV, sheet_name=1,skiprows=[1], usecols=[2,3,4,5,6,12]).fillna(method ='pad')
R_DM_Data = R_DM_Data.rename(columns={"RIGHT FOOT": "Overall Mean(Right)", "LEFT FOOT": "Overall Mean(Left)", "IMC":"BMI"})


sizes = ["0%", "10%", "20%", "30%", "40%"]

CG_L_PATH = ANNOT_PATH+"/CG_L"
CG_R_PATH = ANNOT_PATH + "/CG_R"
DM_L_PATH = ANNOT_PATH + "/DM_L"
DM_R_PATH = ANNOT_PATH + "/DM_R"

def sort_func(path):
  elem = path.name
  key = elem[:-10]
  key = key[3:]
  return int(key)

def write_to_csv(file_name, fields, rows):
  '''
    Input: 
      file_name = Name of the file,
      fields = the columns of the table
      rows = the input rows of the table
    Output: 
  '''
      
  # name of csv file 
  filename = CSV_FILE_PATH + file_name + ".csv"

  
  # writing to csv file 
  with open(filename, 'w') as csvfile: 
      # creating a csv writer object 
      csvwriter = csv.writer(csvfile) 
          
      # writing the fields 
      csvwriter.writerow(fields) 
          
      # writing the data rows 
      csvwriter.writerows(rows)
      
  print(f"Successfully written to {filename}")

glcm_feat = [ "contrast", "ASM", "correlation", "mean", "dissimilarity","homogeneity","energy","skewness","kurtosis","variance"]
def generate_feat_dict(roi_number, feat_arr):
  feat_dict = {}
  # Create empty array for each feat
  for name in feat_arr:
    for i in range(1, roi_number + 1):
      feat_dict[name + "-" + str(i)] = []
    
  return feat_dict

from scipy import stats
import pywt
import pywt.data
from skimage.data import lfw_subset
from skimage.transform import integral_image
from skimage.feature import haar_like_feature
from skimage.feature import haar_like_feature_coord
from skimage.feature import draw_haar_like_feature

def extract_glcm_feat(data, feat_dict, idx):

  patch_normed = data
  patch = patch_normed.astype(np.uint8)
  glcm = greycomatrix(patch, [2], [0], symmetric=True, normed=True)
  feat_dict['dissimilarity-' + str(idx)].append(greycoprops(glcm, 'dissimilarity')[0, 0])
  feat_dict['contrast-' + str(idx)].append(greycoprops(glcm, 'contrast')[0, 0])
  feat_dict['homogeneity-' + str(idx)].append(greycoprops(glcm, 'homogeneity')[0, 0])
  feat_dict['ASM-' + str(idx)].append(greycoprops(glcm, 'ASM')[0, 0])
  feat_dict['energy-' + str(idx)].append(greycoprops(glcm, 'energy')[0, 0])
  feat_dict['correlation-' + str(idx)].append(greycoprops(glcm, 'correlation')[0, 0])
  feat_dict['mean-' + str(idx)].append(np.mean(data))
  return feat_dict

def describe_image_stats(im, feat_dict, idx):
  st = stats.describe(im.flatten())
  feat_dict['skewness-' + str(idx)].append(st.skewness)
  feat_dict['kurtosis-' + str(idx)].append(st.kurtosis)
  feat_dict['variance-' + str(idx)].append(st.variance)
  return feat_dict


feature_types = ['type-2-x', 'type-2-y']

def extract_wavlet_features(data, features):
  all = []
  coeffs2 = pywt.dwt2(data, 'haar')
  for n in coeffs2:
    all.extend(np.array(n).flatten())
  features.extend(all)

def extract_feature_image(img, feature_type, features, feature_coord=None):
    """Extract the haar feature for the current image"""
    ii = integral_image(img)
    X = haar_like_feature(ii, 0, 0, ii.shape[0], ii.shape[1],
                             feature_type=feature_type,
                             feature_coord=feature_coord)
    features.extend(X)

"""## Extract features from ROIs and save them to csv"""

# Current ROI path
roi_inc_index = 4 # 0 -> 0%, 1 -> 10%, 2 -> 20%...
roi_inc_path = f"/roi-{sizes[roi_inc_index]}"
path = Path(DM_R_PATH + roi_inc_path)
path_DL = Path(DM_L_PATH + roi_inc_path)
paths = sorted(list(path.glob("*")), key=sort_func)
pathsDL = sorted(list(path_DL.glob("*")), key=sort_func)
DR_dicts = {}
DL_dicts = {}
DR_text_dict = {}
DL_text_dict = {}
path_list = []
feat_dict = generate_feat_dict(7, glcm_feat)
feat_dict_R = generate_feat_dict(7, glcm_feat)



for idx in range(0, len(paths), 7):
  roi_idx = 1
  paths_arr = paths[idx:idx+7]
  pathsDL_arr = pathsDL[idx:idx+7]

  data_arr=[]
  data_arr_DL=[]
  # Process for right images
  for p in paths_arr:
    data = np.load(Path(p))    
    data_arr.extend(data.flatten())
    describe_image_stats(data,feat_dict_R, roi_idx) # Image statistics
    extract_glcm_feat(data,feat_dict_R, roi_idx) # Extract glcm features Right
    roi_idx = roi_idx + 1
  DR_dicts[str(idx//7)] = data_arr
  
  roi_idx = 1
  features = []
  # Process for left images
  for p in pathsDL_arr:
    data = np.load(Path(p))
    data_arr_DL.extend(data.flatten())
    
    # Extract Features
    describe_image_stats(data,feat_dict, roi_idx) # Image statistics
    extract_glcm_feat(data,feat_dict, roi_idx) # Extract glcm features Left
    extract_feature_image(np.array(data), feature_types,features) # Extract Wavlet features

    roi_idx = roi_idx + 1
    

  DL_dicts[str(idx//7)] = data_arr_DL
  DL_text_dict[str(idx//7)] = features


dataDR = pd.DataFrame.from_dict(DR_dicts, orient='index')
dataDL = pd.DataFrame.from_dict(DL_dicts, orient='index')
data_feat_DL = pd.DataFrame.from_dict(feat_dict)
data_feat_DR = pd.DataFrame.from_dict(feat_dict_R)
data_wavl_DL = pd.DataFrame.from_dict(DL_text_dict, orient='index')
data_feat_DR.tail()

dataDR = dataDR.assign(label = np.ones(122).astype(int))
dataDL = dataDL.assign(label = np.ones(122).astype(int))

#GLCM Labels
data_feat_DL = data_feat_DL.assign(label = np.ones(122).astype(int))
data_feat_DR = data_feat_DR.assign(label = np.ones(122).astype(int))
data_wavl_DL = data_feat_DR.assign(label = np.ones(122).astype(int))


print(data_feat_DR.tail())
print(data_feat_DL.tail())

# Add general data to ROI data
data_feat_DL = pd.concat([R_DM_Data, data_feat_DL],axis=1)
data_feat_DL.head()
data_feat_DR = pd.concat([R_DM_Data, data_feat_DR],axis=1)
data_feat_DR.head()

path = Path(CG_R_PATH + roi_inc_path)
path_CL = Path(CG_L_PATH + roi_inc_path)

pathsCL = sorted(list(path_CL.glob("*")), key=sort_func)
paths = sorted(list(path.glob("*")), key=sort_func)

CR_dicts = {}
CL_dicts = {}
CR_text_dict = {}
CL_text_dict = {}
path_list = []
feat_dict = generate_feat_dict(7, glcm_feat)
feat_dict_CR = generate_feat_dict(7, glcm_feat)

for idx in range(0, len(paths), 7):
  paths_arr = paths[idx:idx+7]
  paths_arr_CL = pathsCL[idx:idx+7]
  data_arr=[]
  data_arr_CL=[]
  roi_idx = 1
  for p in paths_arr:
    path_list.append(p.name)
    data = np.load(Path(p))
    # Extract Features
    describe_image_stats(data,feat_dict_CR, roi_idx) # Image statistics
    extract_glcm_feat(data,feat_dict_CR, roi_idx) # Extract GLCM features
    roi_idx = roi_idx + 1
    data_arr.extend(data.flatten())
    
  CR_dicts[str(idx//7)] = data_arr
  

  roi_idx = 1
  for p in paths_arr_CL:
    data = np.load(Path(p))
    data_arr_CL.extend(data.flatten())
    # Extract Features
    describe_image_stats(data,feat_dict, roi_idx) # Image statistics
    extract_glcm_feat(data,feat_dict, roi_idx) # Extract GLCM features
    extract_feature_image(np.array(data), feature_types,features) # Haar Features
    roi_idx = roi_idx + 1

  CL_dicts[str(idx//7)] = data_arr_CL

dataCL = pd.DataFrame.from_dict(CL_dicts, orient='index')
dataCR = pd.DataFrame.from_dict(CR_dicts,orient='index')
data_wavl_CL = pd.DataFrame.from_dict(CL_text_dict, orient='index')
data_feat_CL = pd.DataFrame.from_dict(feat_dict)
data_feat_CR = pd.DataFrame.from_dict(feat_dict_CR)

dataCR = dataCR.assign(label = np.zeros(45).astype(int))
dataCL = dataCL.assign(label = np.zeros(45).astype(int))

# GLCM Labels
data_feat_CL = data_feat_CL.assign(label = np.zeros(45).astype(int))
data_feat_CR = data_feat_CR.assign(label = np.zeros(45).astype(int))

data_wavl_CL = data_wavl_CL.assign(label = np.zeros(45).astype(int))


print(data_feat_CL.head())
print(data_feat_CR.head())

# Add general data to ROI data
data_feat_CL = pd.concat([R_CG_Data, data_feat_CL],axis=1)
data_feat_CR = pd.concat([R_CG_Data, data_feat_CR],axis=1)
#data_feat_CL.head()
data_feat_CR.head()

AllDataDF = pd.concat([dataDR, dataCR])
# LEFT Features
AllFeatDF = pd.concat([data_feat_CL, data_feat_DL])
# Right Features
AllFeatDR = pd.concat([data_feat_CR, data_feat_DR])


AllWavDF = pd.concat([data_wavl_DL, data_wavl_CL])
AllDataDFL = pd.concat([dataDL, dataCL])


AllData = pd.concat([AllDataDF, AllDataDFL], axis=1)
AllDataDF = AllFeatDF
AllDataDR = AllFeatDR
AllCombinedData = pd.concat([AllFeatDF, AllFeatDR], axis=1)
AllDataDR.head()

AllDataDF.to_csv(CSV_FILE_PATH+f"All-glcm-{sizes[roi_inc_index]}-stats.csv")
AllDataDR.to_csv(CSV_FILE_PATH+f"AllR-glcm-{sizes[roi_inc_index]}-stats.csv")
#AllCombinedData.to_csv(CSV_FILE_PATH+"All-combined-larger-stats.csv")

print(AllDataDR.head())

AllDataDF.columns

import seaborn as sns
def plot_heatmap(dataframe, title="Coorelation of extracted features"):
  Var_Corr = dataframe.corr()
  # plot the heatmap and annotation on it
  sns.heatmap(Var_Corr, xticklabels=Var_Corr.columns, yticklabels=Var_Corr.columns)
  plt.title(title)
  plt.show()

X_raw = AllDataDF[AllDataDF.columns[:-1]].fillna(method="pad") # Features
y_raw = AllDataDF.label.fillna(method="pad") # Target variable
print(f'X shape {X_raw.shape}, y shape {y_raw.shape}')

# Difference in mean plots
DL_mean = dataDL[range(0,366)].mean(axis=1).values
CL_mean = dataCL[range(0,366)].mean(axis=1).values
# sns.displot(DL_mean)
# plt.xlabel("DL Mean")
# plt.ylabel("Count")
# plt.show()
# plt.figure()
# sns.displot(CL_mean)
# plt.xlabel("CL Mean")
# plt.ylabel("Count")
# plt.show()

print(f'DL Mean: {np.mean(DL_mean)} {np.std(DL_mean)}')
print(f'CL Mean: {np.mean(CL_mean)} {np.std(DL_mean)}')

# Select features using example
from sklearn.datasets import make_classification
from sklearn import preprocessing
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
# define feature selection
fs = SelectKBest(score_func=f_classif, k=25)
# apply feature selection
X_val= X_raw[X_raw.columns[1:]]
X_selected = fs.fit_transform(X_val,y_raw)
feat_cols = X_val.columns[(fs.get_support())]
X_selected = X_val[feat_cols]
print(X_selected.shape)

cols = X_selected.columns
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(X_selected.values)
X = pd.DataFrame(x_scaled, columns=cols)
X.tail()

plt.rcParams["figure.figsize"] = (15, 15)
plot_heatmap(AllCombinedData)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline


# Define model
sel_ = SelectFromModel(LogisticRegression(C=100, penalty='l2'))
sel_.fit(X, y)

# Perform the search
# results = model.fit(X_train, y_train)
# predictions = model.predict(X_test)

selected_feat = X.columns[(sel_.get_support())]
print('total features: {}'.format((X.shape[1])))
print('selected features: {}'.format(len(selected_feat)))
print('features with coefficients shrank to zero: {}'.format(
      np.sum(sel_.estimator_.coef_ == 0)))

# Scale and Normalize
from sklearn import preprocessing
x = X[selected_feat].values #returns a numpy array
cols = X[selected_feat].columns
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
X = pd.DataFrame(x_scaled, columns=cols)
X.tail()

X = pd.DataFrame(X_raw.values, columns=X_raw.columns)

# Split X and y into training and testing sets
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score

X_train,X_test,y_train,y_test=train_test_split(X_raw,y_raw,test_size=0.30, shuffle=True)
print(X_train.shape[0], X_train.shape[1], X_test.shape[0], y_test.shape[0])

fields = ["K-folds", "CV Accuracy", "ROC-AUC Score", "Precision", "Recall", "Test Accuracy", "Test Precision", "Test Recall", "Test ROC-AUC"]

kfolds =[3, 5, 10]
row = []
for i in kfolds:
  cv = RepeatedKFold(n_splits=i,n_repeats=3)
  param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','poly']}
  svc=svm.SVC(probability=True, random_state=5)
  model=RandomizedSearchCV(svc,param_grid, cv=cv)
  # Fit SVC Model
  model.fit(X_train, y_train)
  y2 = model.predict(X_test)
  # Calculate CV score
  scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)
  precision = cross_val_score(model, X_train, y_train, scoring='precision', cv=cv, n_jobs=-1)
  recall = cross_val_score(model, X_train, y_train, scoring='recall', cv=cv, n_jobs=-1)
  roc_auc = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)

  # test eval metrics
  test_acc = accuracy_score(y_test,y2)
  test_recall = recall_score(y_test,y2)
  test_precision = precision_score(y_test,y2)
  test_roc = roc_auc_score(y_test,y2)

  print(model.best_estimator_)

  # report performance
  cv_acc = "{:.3f} ({:.3f})".format(np.mean(scores), np.std(scores))
  roc = "{:.3f} ({:.3f})".format(np.mean(roc_auc), np.std(roc_auc))
  recall = "{:.3f} ({:.3f})".format(np.mean(recall), np.std(recall))
  precision = "{:.3f} ({:.3f})".format(np.mean(precision), np.std(precision))

  test_acc =  "{:.3f} ({:.3f})".format(np.mean(test_acc), np.std(test_acc))
  test_rec =  "{:.3f} ({:.3f})".format(np.mean(test_recall), np.std(test_recall))
  test_prec = "{:.3f} ({:.3f})".format(np.mean(test_precision), np.std(test_precision))
  test_roc = "{:.3f} ({:.3f})".format(np.mean(test_roc), np.std(test_roc))
  row.append([i,cv_acc, roc, precision, recall, test_acc, test_prec, test_rec, test_roc])
  
  print('CV Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))
  print("Test Accuracy: ", test_acc)
  print("Test ROC: ", test_roc)

write_to_csv("CV-svm-test-all-features", fields, row)

from sklearn.model_selection import RandomizedSearchCV

kfolds =[3, 5, 10]
row = []
for i in kfolds:

  cv = KFold(n_splits=i, shuffle=True)
  params = { 'max_depth': [3, 5, 6, 10, 15, 20],
            'learning_rate': [0.01, 0.1, 0.2, 0.3],
            'subsample': np.arange(0.5, 1.0, 0.1),
            'colsample_bytree': np.arange(0.4, 1.0, 0.1),
            'colsample_bylevel': np.arange(0.4, 1.0, 0.1),
            'n_estimators': [100, 500, 1000]}
  model = XGBClassifier()
  model=RandomizedSearchCV(estimator=model,
                         param_distributions=params,
                         scoring='accuracy',
                         n_iter=20,
                         cv=cv,
                         verbose=1)
  # Fit SVC Model
  model.fit(X_train, y_train)
  y2 = model.predict(X_test)
  # Calculate CV score
  scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)
  precision = cross_val_score(model, X_train, y_train, scoring='precision', cv=cv, n_jobs=-1)
  recall = cross_val_score(model, X_train, y_train, scoring='recall', cv=cv, n_jobs=-1)
  roc_auc = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)

  print(model.best_estimator_)

  # test eval metrics
  test_acc = accuracy_score(y_test,y2)
  test_recall = recall_score(y_test,y2)
  test_precision = precision_score(y_test,y2)
  test_roc = roc_auc_score(y_test,y2)



  # report performance
  cv_acc = "{:.3f} ({:.3f})".format(np.mean(scores), np.std(scores))
  roc = "{:.3f} ({:.3f})".format(np.mean(roc_auc), np.std(roc_auc))
  recall = "{:.3f} ({:.3f})".format(np.mean(recall), np.std(recall))
  precision = "{:.3f} ({:.3f})".format(np.mean(precision), np.std(precision))

  test_acc =  "{:.3f} ({:.3f})".format(np.mean(test_acc), np.std(test_acc))
  test_rec =  "{:.3f} ({:.3f})".format(np.mean(test_recall), np.std(test_recall))
  test_prec = "{:.3f} ({:.3f})".format(np.mean(test_precision), np.std(test_precision))
  test_roc = "{:.3f} ({:.3f})".format(np.mean(test_roc), np.std(test_roc))
  row.append([i,cv_acc, roc, precision, recall, test_acc, test_prec, test_rec, test_roc])
  
  print('CV Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))
  print("Test Accuracy: ", test_acc)
  print("Test ROC: ", test_roc)

write_to_csv("xgb-K-folds-RS-all-test", fields, row)

from sklearn.metrics import classification_report,plot_roc_curve
print(classification_report(y_test,y2))
plot_roc_curve(model, X_test, y_test)

from xgboost import plot_importance
plt.rcParams["figure.figsize"] = (20, 20)
plot_importance(model.best_estimator_)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y2)
cm_display = ConfusionMatrixDisplay(cm).plot()

# import the class
from sklearn.linear_model import LogisticRegression

# instantiate the model (using the default parameters)
logreg = LogisticRegression()

# fit the model with data
logreg.fit(X_train,y_train)

# Predictions
y_pred=logreg.predict(X_test)

# import the metrics class
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

print(f"Test Accuracy: {metrics.accuracy_score(y_test, y_pred)} {metrics.precision_score(y_test, y_pred)} {metrics.recall_score(y_test, y_pred)} {metrics.f1_score(y_test, y_pred)}")

from sklearn import svm
svc=svm.SVC()
svc.fit(X_train, y_train)
y2 = svc.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy: ",accuracy_score(y_test,y2))
from sklearn.metrics import classification_report
print(classification_report(y_test,y2))
print(f"{metrics.accuracy_score(y_test, y2)},{metrics.precision_score(y_test, y2)},{metrics.recall_score(y_test, y2)},{metrics.f1_score(y_test, y2)}, {metrics.roc_auc_score(y_test, y2)}")

from numpy import sort
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import SelectFromModel
from sklearn import metrics
from sklearn.model_selection import KFold, RepeatedKFold
from sklearn.model_selection import cross_val_score
import warnings
warnings.filterwarnings('ignore')

# fit model on all training data
cv = KFold(n_splits=5, random_state=1, shuffle=True)
model = XGBClassifier()
model = GridSearchCV(model,param_grid={'n_estimators':[50,75,100],'max_depth':[2,3,4,5,10], 'learning_rate':[0.1, 0.01,0.5,0.05]},cv=cv)
model.fit(X_train, y_train)
# make predictions for test data and evaluate
pred_train = model.predict(X_train)
predictions = model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

# evaluate model
scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))


print(classification_report(y_test,predictions))

print(model.best_estimator_)
# Fit model using each importance as a threshold
# thresholds = sort(model.feature_importances_)

# for thresh in thresholds:
#   # select features using threshold
#   selection = SelectFromModel(model, threshold=thresh, prefit=True)
#   select_X_train = selection.transform(X_train)
#   # train model
#   selection_model = XGBClassifier()
#   selection_model.fit(select_X_train, y_train)
# 	# eval model
#   select_X_test = selection.transform(X_test)
#   predictions = selection_model.predict(select_X_test)
#   accuracy = metrics.accuracy_score(y_test, predictions)
#   precision = metrics.precision_score(y_test, predictions)
#   recall = metrics.recall_score(y_test, predictions)
#   f1 = metrics.f1_score(y_test, predictions)
#   print("n=%d,%.2f%%,%.2f,%.2f,%.2f" % ( select_X_train.shape[1], accuracy*100.0, precision, recall, f1))
#   #print(f"{metrics.accuracy_score(y_test, predictions)},{metrics.precision_score(y_test, predictions)},{metrics.recall_score(y_test, predictions)},{metrics.f1_score(y_test, predictions)}")

# Fit model using each importance as a threshold
model = model.best_estimator_
thresholds = sort(model.feature_importances_)

for thresh in thresholds:
  # select features using threshold
  selection = SelectFromModel(model, threshold=thresh, prefit=True)
  select_X_train = selection.transform(X_train)
  # train model
  selection_model = XGBClassifier()
  selection_model.fit(select_X_train, y_train)
	# eval model
  select_X_test = selection.transform(X_test)
  predictions = selection_model.predict(select_X_test)
  accuracy = metrics.accuracy_score(y_test, predictions)
  precision = metrics.precision_score(y_test, predictions)
  recall = metrics.recall_score(y_test, predictions)
  f1 = metrics.f1_score(y_test, predictions)
  print("n=%d,%.2f%%,%.2f,%.2f,%.2f" % ( select_X_train.shape[1], accuracy*100.0, precision, recall, f1))
  #print(f"{metrics.accuracy_score(y_test, predictions)},{metrics.precision_score(y_test, predictions)},{metrics.recall_score(y_test, predictions)},{metrics.f1_score(y_test, predictions)}")

from xgboost import plot_importance
plt.rcParams["figure.figsize"] = (20, 20)
plot_importance(model.best_estimator_)

"""## We will extract GLCM features now and compare them"""

import matplotlib.pyplot as plt
import cv2
from google.colab.patches import cv2_imshow

DATA_PATH = "/content/drive/MyDrive/UM_MSC/Research_Thermal_Imaging/data/ThermoDataBase"
IMG_PATH = DATA_PATH + "/images"
TEST_PATH = DATA_PATH + "/test"
TEST_IMAGE_PATH = TEST_PATH + "/images"
ANNOT_PATH = TEST_PATH + "/annot_data"


path = Path(ANNOT_PATH)
fixed_images = []
pred_images = []
fixed_annotations = []
pred_annotations = []
for p in sorted(path.rglob("*")):
  start_name = p.name
  my_file = Path(p)
  if start_name.startswith('fixed-annotations'):
    fixed_annotations.append(np.load(my_file))
  elif start_name.startswith("pred-annotations"):
    pred_annotations.append(np.load(my_file))
  elif start_name.startswith("pred"):
    pred_images.append(np.load(my_file))
  elif start_name.startswith("fixed"): 
    fixed_images.append(np.load(my_file))
  else: 
    break;

print(f'Pred Images {len(pred_images)}')
print(f'Fixed Images {len(fixed_images)}')
print(f'Pred Annot {len(pred_annotations)}')
print(f'Fixed Annot {len(fixed_annotations)}')

control_cutoff_idx = 42
control = pred_images[:control_cutoff_idx]
diab = pred_images[control_cutoff_idx:]
control_annot = pred_annotations[:control_cutoff_idx]
diab_annot = pred_annotations[control_cutoff_idx:]
test_control = control[4]
test_c_annot = control_annot[4]
test_diab = diab[6]
test_d_annot = diab_annot[6]

## GLCM Feature Extraction
from skimage.feature import greycomatrix, greycoprops
from skimage import data
import matplotlib.pyplot as plt
from math import floor

PATCH_SIZE = 5

# open the camera image
image = test_control
d_image = test_diab

# select some patches from grassy areas of the image
c_locations = test_c_annot
c_patches = []
for idx, loc in enumerate(c_locations):
    SF = 1
    if(idx % 6 == 0 or idx % 7 == 0):
      SF = 2
    startx = int(floor(loc[1]))
    endx = startx+PATCH_SIZE
    starty = int(floor(loc[0]))
    endy = starty+PATCH_SIZE
    c_patches.append(image[startx:endx, starty:endy])

# select some patches from sky areas of the image
d_locations = test_d_annot
d_patches = []
for idx, loc in enumerate(d_locations):
    SF = 1
    if(idx % 6 == 0 or idx % 7 == 0):
      SF = 2
    startx = int(floor(loc[1]))
    endx = startx+PATCH_SIZE*SF
    starty = int(floor(loc[0]))
    endy = starty+PATCH_SIZE*SF
    d_patches.append(d_image[startx:endx, starty:endy])

# compute some GLCM properties each patch
xs = []
ys = []
for i, patch in enumerate(c_patches + d_patches):
    patch_normed = patch * 255
    patch = patch_normed.astype(np.uint8)
    glcm = greycomatrix(patch, [2], [0], symmetric=True, normed=True)
    xs.append(greycoprops(glcm, 'dissimilarity')[0, 0])
    ys.append(greycoprops(glcm, 'correlation')[0, 0])

# create the figure
plt.figure(figsize=(8, 8))

# display the image patches
for i, patch in enumerate(c_patches):
    plt.subplot(3, len(c_patches), len(c_patches) * 1 + i + 1)
    plt.imshow(patch, cmap=plt.cm.gray)
    plt.xlabel('Control %d' % (i + 1))

for i, patch in enumerate(d_patches):
    plt.subplot(3, len(d_patches), len(d_patches) * 2 + i + 1)
    plt.imshow(patch, cmap=plt.cm.gray)
    plt.xlabel('Diabetic %d' % (i + 1))

# display original image with locations of patches
plt.subplot(3, 4, 1)
plt.imshow(image, cmap=plt.cm.gray)
for (x, y) in c_locations:
    plt.plot(x + PATCH_SIZE / 2, y + PATCH_SIZE / 2, 'gs')
plt.xlabel('Control Image')
plt.xticks([])
plt.yticks([])
plt.axis('image')

plt.subplot(3, 4, 2)
plt.imshow(d_image, cmap=plt.cm.gray)
for (x, y) in d_locations:
    plt.plot(x + PATCH_SIZE / 2, y + PATCH_SIZE / 2, 'bs')
plt.xlabel('Diabetic Image')
plt.xticks([])
plt.yticks([])
plt.axis('image')

# for each patch, plot (dissimilarity, correlation)
plt.subplot(3, 3, 3)
plt.plot(xs[:len(c_patches)], ys[:len(c_patches)], 'go',
         label='Control')
plt.plot(xs[len(c_patches):], ys[len(c_patches):], 'bo',
         label='Diabetic')
plt.xlabel('GLCM Dissimilarity')
plt.ylabel('GLVM Correlation')
plt.legend()

# display the patches and plot
plt.suptitle('Grey level co-occurrence matrix features', fontsize=14)
plt.show()

feature_cols = feat_names + ["mean"]

# Choose only certain ROIs
ROI_index = 6
data_filtered = dataF
# data_filtered = dataF[dataF['loc'] == ROI_index]
data_filtered.describe()

X = data_filtered[feature_cols] # Features
y = data_filtered.label # Target variable

import seaborn as sns
Var_Corr = data_filtered.drop("loc",axis=1).corr()
# plot the heatmap and annotation on it
sns.heatmap(Var_Corr, xticklabels=Var_Corr.columns, yticklabels=Var_Corr.columns, annot=True)
plt.title("Coorelation of extracted features")
plt.show()

# Scale and Normalize
from sklearn import preprocessing
x = X.values #returns a numpy array
cols = X.columns
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
X = pd.DataFrame(x_scaled, columns=cols)
X.tail()

# Split X and y into training and testing sets
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0, shuffle=True)

# import the class
from sklearn.linear_model import LogisticRegression

# instantiate the model (using the default parameters)
logreg = LogisticRegression()

# fit the model with data
logreg.fit(X_train,y_train)

# Predictions
y_pred=logreg.predict(X_test)

# import the metrics class
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print("Precision:",metrics.precision_score(y_test, y_pred))
print("Recall:",metrics.recall_score(y_test, y_pred))
print(f"{metrics.accuracy_score(y_test, y_pred)} {metrics.precision_score(y_test, y_pred)} {metrics.recall_score(y_test, y_pred)} {metrics.f1_score(y_test, y_pred)}")

y_pred_proba = logreg.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.legend(loc=4)
plt.title("Logistic Regression Model on Extracted Features")
plt.show()

from sklearn import svm
svc=svm.SVC()
svc.fit(X_train, y_train)
y2 = svc.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy: ",accuracy_score(y_test,y2))
from sklearn.metrics import classification_report
print(classification_report(y_test,y2))
print(f"{metrics.accuracy_score(y_test, y2)},{metrics.precision_score(y_test, y2)},{metrics.recall_score(y_test, y2)},{metrics.f1_score(y_test, y2)}")

from IPython.core.pylabtools import figsize
# plot feature importance using built-in function
from xgboost import XGBClassifier
from xgboost import plot_importance
from matplotlib import pyplot
plt.rcParams["figure.figsize"] = (20, 20)
# split data into X and y
X = X_train
y = y_train
# fit model no training data
model = XGBClassifier()
model.fit(X, y)
# plot feature importance
plt.figure(figsize=(20,20))
plot_importance(model)
pyplot.show()

from numpy import sort
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import SelectFromModel
from sklearn import metrics
import warnings
warnings.filterwarnings('ignore')

# fit model on all training data
model = XGBClassifier()
# model = GridSearchCV(model,param_grid={'n_estimators':[50,75,100]})
model.fit(X_train, y_train)
# make predictions for test data and evaluate
predictions = model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))
# Fit model using each importance as a threshold
# thresholds = sort(model.feature_importances_)

# for thresh in thresholds:
#   # select features using threshold
#   selection = SelectFromModel(model, threshold=thresh, prefit=True)
#   select_X_train = selection.transform(X_train)
#   # train model
#   selection_model = XGBClassifier()
#   selection_model.fit(select_X_train, y_train)
# 	# eval model
#   select_X_test = selection.transform(X_test)
#   predictions = selection_model.predict(select_X_test)
#   accuracy = metrics.accuracy_score(y_test, predictions)
#   precision = metrics.precision_score(y_test, predictions)
#   recall = metrics.recall_score(y_test, predictions)
#   f1 = metrics.f1_score(y_test, predictions)
#   print("n=%d,%.2f%%,%.2f,%.2f,%.2f" % ( select_X_train.shape[1], accuracy*100.0, precision, recall, f1))
#   #print(f"{metrics.accuracy_score(y_test, predictions)},{metrics.precision_score(y_test, predictions)},{metrics.recall_score(y_test, predictions)},{metrics.f1_score(y_test, predictions)}")

from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y2)
cm_display = ConfusionMatrixDisplay(cm).plot()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Lasso, LogisticRegression
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import StandardScaler

# Define model
sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2'))
sel_.fit(X_train, y_train)
sel_.get_support()

# Perform the search
# results = model.fit(X_train, y_train)
# predictions = model.predict(X_test)

selected_feat = X_train.columns[(sel_.get_support())]
print('total features: {}'.format((X_train.shape[1])))
print('selected features: {}'.format(len(selected_feat)))
print('features with coefficients shrank to zero: {}'.format(
      np.sum(sel_.estimator_.coef_ == 0)))

selected_feat

